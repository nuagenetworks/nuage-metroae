- name: Clean known_hosts of VSTATs (ignoring errors)
  known_hosts:
    name: "{{ hostname }}"
    state: absent
  delegate_to: localhost
  no_log: True
  ignore_errors: True

- name: Wait for VSTAT ssh to be ready
  include_role:
    name: common
    tasks_from: wait-for-ssh
  vars:
    ssh_host: "{{ mgmt_ip }}"
    host_username: "{{ vstat_default_username }}"
    retries: 90

- import_tasks: openstack.yml
  when: target_server_type is match("openstack")
  tags:
    - vstat
    - openstack
    - vstat-deploy

- block:
  - name: Force DHCP update to configure DNS in AWS (ignoring errors)
    command: dhclient
    ignore_errors: true

  - name: Set hostname for AWS for current session
    command: "hostname {{ hostname }}"

  - name: Set hostname for AWS permanently
    shell: "echo {{ hostname }} > /etc/hostname"

  when: target_server_type is match("aws")
  remote_user: "{{ vstat_default_username }}"

- name: Get vsd node(s) information
  import_role:
    name: common
    tasks_from: vsd-node-info.yml
  vars:
    vsd_hostname: "{{ vsd_fqdn }}"

- block:
  - name: Generate SSH keys
    include_role:
      name: common
      tasks_from: vstat_generate_ssh_keys.yml
    with_items:
      - "{{ groups['vstats'] }}"
    loop_control:
      loop_var: vstat
    vars:
      vstat_username: "{{ vstat_default_username }}"
      group_vstats: "{{ groups['vstats'] }}"

    when: groups['vstats'] is defined

  - name: Generate SSH keys
    include_role:
      name: common
      tasks_from: vstat_generate_ssh_keys.yml
    with_items:
      - "{{ groups['primary_vstats'] }}"
    loop_control:
      loop_var: vstat
    vars:
      vstat_username: "{{ vstat_default_username }}"
      group_vstats: "{{ groups['primary_vstats'] }}"

    when: groups['primary_vstats'] is defined and active

  - name: Generate SSH keys
    include_role:
      name: common
      tasks_from: vstat_generate_ssh_keys.yml
    with_items:
      - "{{ groups['backup_vstats'] }}"
    loop_control:
      loop_var: vstat
    vars:
      vstat_username: "{{ vstat_default_username }}"
      group_vstats: "{{ groups['backup_vstats'] }}"

    when: groups['backup_vstats'] is defined and not active

  run_once: true
  when: vstat_sa_or_ha is match('ha')

- name: check for iptables (ignoring errors)
  shell:                                # noqa 301 305
    cmd: "service iptables status"
    warn: no
  register: _svc_iptables
  ignore_errors: True
  remote_user: "{{ vstat_default_username }}"

- name: Print vsd deployment mode when verbosity >= 1
  debug: var=vsd_sa_or_ha

- block:

  - name: Start iptables
    systemd:
      name: iptables
      state: started
    remote_user: "{{ vstat_default_username }}"

  - name: Enable iptables on boot
    systemd:
      name: iptables
      enabled: yes
    remote_user: "{{ vstat_default_username }}"

  - name: Check if ip6tables is already setup for VSD rules (ignoring errors)
    shell: ip6tables -L INPUT | grep 'match-set vsd src'
    remote_user: "{{ vstat_default_username }}"
    register: vstat_ip6tables_result
    ignore_errors: True
    when: enable_ipv6 | default(False)

  - name: Check if iptables is already setup for VSD rules (ignoring errors)
    shell: iptables -L INPUT | grep 'match-set vsd src'
    remote_user: "{{ vstat_default_username }}"
    register: vstat_iptables_result
    ignore_errors: True
    when: not enable_ipv6 | default(True)

  - name: Set if skipping VSTAT deploy
    set_fact:
      skip_vstat_deploy: >-
        {{ (vstat_iptables_result is defined and vstat_iptables_result.rc | default(1) == 0) or
           (vstat_ip6tables_result is defined and vstat_ip6tables_result.rc | default(1) == 0) }}

  - name: Display if skipping VSTAT deploy
    debug:
      msg:
        - "***************************************************"
        - "Skipping VSTAT deploy because it is already running"
        - "***************************************************"
    when: skip_vstat_deploy

  - block:

    - block:

      - name: Create iptables vars file on ansible host
        template: src="{{ role_path }}/templates/iptables.j2" dest="{{ role_path }}/vars/iptables.yml" backup=no mode=0755

      - name: Include variable file.
        include_vars: "{{ role_path }}/vars/iptables.yml"

      delegate_to: localhost

    - block:

      - name: Config iptables on VSTAT vm to accept conn on ports 9200,9300 from vsd(s) (ignoring errors)
        shell: "{{ item }}"
        with_items:
          - "{{ iptables_std_commands }}"
        remote_user: "{{ vstat_default_username }}"
        register: iptables_results
        ignore_errors: True

      - name: Verify iptables rules installation
        assert:
          that: "{{ item.rc }} == 0 or
                 {{ item.stderr is search('already exists') }} or
                 {{ item.stderr is search('already added') }}"
          msg: "iptables rule was not installed"
        with_items:
          - "{{ iptables_results.results }}"

      when: vsd_sa_or_ha is match('sa')

    - block:

      - name: Config iptables on VSTAT vm to accept conn on ports 9200, 9300 from vsd(s) in cluster setup (ignoring errors)
        shell:
          cmd: "{{ item }}"
          warn: no
        with_items:
          - "{{ iptables_cluster_commands }}"
        remote_user: "{{ vstat_default_username }}"
        register: iptables_results
        ignore_errors: True

      - name: Verify iptables rules installation
        assert:
          that: "{{ item.rc }} == 0 or
                 {{ item.stderr is search('already exists') }} or
                 {{ item.stderr is search('already added') }}"
          msg: "iptables rule was not installed"
        with_items:
          - "{{ iptables_results.results }}"

      when: vsd_sa_or_ha is match('ha')

    when: not skip_vstat_deploy

  when: "_svc_iptables.rc == 0"

- name: check for firewalld (ignoring errors)
  shell:
    cmd: "service firewalld status"     # noqa 301 305
    warn: no
  register: _svc_firewalld
  ignore_errors: True
  remote_user: "{{ vstat_default_username }}"

- block:

  - name: Start firewalld
    systemd:
      name: firewalld
      state: started
    remote_user: "{{ vstat_default_username }}"

  - name: Enable firewalld on boot
    systemd:
      name: firewalld
      enabled: yes
    remote_user: "{{ vstat_default_username }}"

  - name: Check if firewalld is already setup for VSD rules (ignoring errors)
    shell: firewall-cmd --list-all | grep 9200 | grep accept
    remote_user: "{{ target_server_username }}"
    become: "{{ 'no' if target_server_username == 'root' else 'yes' }}"
    register: vstat_firewalld_result
    ignore_errors: True

  - name: Set if skipping VSTAT deploy
    set_fact: skip_vstat_deploy="{{ vstat_firewalld_result is defined and vstat_firewalld_result.rc == 0 }}"

  - name: Display if skipping VSTAT deploy
    debug:
      msg:
        - "***************************************************"
        - "Skipping VSTAT deploy because it is already running"
        - "***************************************************"
    when: skip_vstat_deploy

  - block:

    - block:

      - name: Create firewall vars file on ansible host
        template: src="{{ role_path }}/templates/firewall.j2" dest="/tmp/main.yml" backup=no mode=0755

      - name: Include variable file.
        include_vars: /tmp/main.yml

      delegate_to: localhost

    - name: Config firewall on VSTAT vm to accept conn on ports 9200,9300 from vsd(s)
      shell: "{{ item }}"
      with_items:
        - "{{ firewall_std_commands }}"
      remote_user: "{{ vstat_default_username }}"
      when: vsd_sa_or_ha is match('sa')

    - name: Config firewall on VSTAT vm to accept conn on ports 9200, 9300 from vsd(s) in cluster setup
      shell: "{{ item }}"
      with_items:
        - "{{ firewall_cluster_commands }}"
      when: vsd_sa_or_ha is match('ha')
      remote_user: "{{ vstat_default_username }}"

    when: not skip_vstat_deploy

  when:
    - "_svc_firewalld.rc == 0"
    - "_svc_iptables.rc != 0"

- block:

  - import_tasks: add_extra_disk.yml

  - name: Update /etc/hosts file on VSTAT
    lineinfile:
      dest: /etc/hosts
      line: "{{ hostvars[item]['mgmt_ip'] }}    {{ hostvars[item]['hostname'] }}"
    with_items:
      - "{{ groups['vstats'] | default([]) }}"
      - "{{ groups['primary_vstats'] | default([]) }}"
      - "{{ groups['backup_vstats'] | default([]) }}"
      - "{{ groups['data_vstats'] | default([]) }}"
      - "{{ groups['add_data_vstats'] | default([]) }}"

    when: vsd_sa_or_ha is match('ha')
    remote_user: "{{ vstat_default_username }}"

  - name: Configure ntpd and ntpdate and local time zone
    include_role:
      name: common
      tasks_from: linux-ntp-sync
    vars:
      rem_user: "{{ vstat_default_username }}"

  - name: Stop elastic search
    systemd:
      name: elasticsearch
      state: stopped
    remote_user: "{{ vstat_default_username }}"

  - block:

    - name: Get vsd node(s) information
      import_role:
        name: common
        tasks_from: vsd-node-info.yml
      vars:
        vsd_hostname: "{{ vsd_fqdn }}"

    - name: SSH host
      set_fact:
        vsd_node1_hostname: "{{ vsd_hostname_list[0] }}"

    - name: Make sure the first VSD node is ready before we proceed
      include_role:
        name: common
        tasks_from: wait-for-ssh
      vars:
        ssh_host: "{{ vsd_node1_hostname }}"
        host_username: "{{ hostvars[vsd_node1_hostname].vsd_custom_username | default(vsd_custom_username | default(vsd_default_username)) }}"

    - block:

      - block:

        - name: Stat the standalone script
          stat: path=/opt/vsd/vsd-es-standalone.sh
          register: es_sa_script

        - name: Execute VSTAT standalone script on standalone or clustered vsds
          command: /opt/vsd/vsd-es-standalone.sh -e {{ inventory_hostname }}
          no_log: "{{ lookup('env', 'METROAE_NO_LOG') or 'true' }}"
          environment:
            SSHPASS: "{{ vstat_default_password }}"
          when:
            - es_sa_script.stat.exists
            - vstat_default_username == 'root'

        - name: Execute VSTAT standalone script on standalone or clustered vsds
          command: /opt/vsd/vsd-es-standalone.sh -e {{ inventory_hostname }}
          no_log: "{{ lookup('env', 'METROAE_NO_LOG') or 'true' }}"
          when:
            - es_sa_script.stat.exists
            - vstat_default_username != 'root'

        when:
          - vstat_sa_or_ha is match('sa')

      - block:

        - block: 

          - name: Define data only VSTATs for cluster
            set_fact:
              data_group_params: " -d {{ groups['data_vstats'][0] }},{{ groups['data_vstats'][1] }},{{ groups['data_vstats'][2] }}"
            when: groups['add_data_vstats'] is not defined

          - name: Define data only VSTATs for cluster
            set_fact:
              data_group_params: " -d {{ groups['data_vstats'][0] }},{{ groups['data_vstats'][1] }},{{ groups['data_vstats'][2] }}"
            when: groups['add_data_vstats'] is defined and add_extra_3_data_nodes

          - name: Define data only VSTATs for cluster
            set_fact:
              data_group_params: " -d {{ groups['data_vstats'][0] }},{{ groups['data_vstats'][1] }},{{ groups['data_vstats'][2] }},{{ groups['add_data_vstats'][0] }},{{ groups['add_data_vstats'][1] }},{{ groups['add_data_vstats'][2] }}"
            when: groups['add_data_vstats'] is defined and not add_extra_3_data_nodes
          
          when: stats_out | default(false)

        - name: Execute VSTAT cluster script on standalone or clustered vsds (ignoring errors)
          command: /opt/vsd/vsd-es-cluster-config.sh -e {{ groups['vstats'][0] }},{{ groups['vstats'][1] }},{{ groups['vstats'][2] }}{{ data_group_params | default('') }}
          environment:
            SSHPASS: "{{ vstat_default_password }}"
          no_log: "{{ lookup('env', 'METROAE_NO_LOG') or 'true' }}"
          when: groups['vstats'] is defined
          retries: 3
          delay: 10
          register: result
          until: result.rc == 0 or result.stdout is search('may be running elasticsearch already')
          ignore_errors: True

        - name: Assert that cluster script was successful
          assert:
            that: result.stdout is search('may be running elasticsearch already')
            msg: "Cluster script may not have been successfully executed. Check the execution output below for more details. {{ result.stdout }}"
          when: groups['vstats'] is defined and result.rc != 0

        - name: Execute VSTAT cluster script on standalone or clustered vsds for primary vstats
          command: /opt/vsd/vsd-es-cluster-config.sh -e {{ groups['primary_vstats'][0] }},{{ groups['primary_vstats'][1] }},{{ groups['primary_vstats'][2] }}
          environment:
            SSHPASS: "{{ vstat_default_password }}"
          no_log: "{{ lookup('env', 'METROAE_NO_LOG') or 'true' }}"
          when: groups['primary_vstats'] is defined and active
          retries: 3
          delay: 10
          register: result
          until: result.rc == 0 or result.stdout is search('may be running elasticsearch already')
          ignore_errors: True

        - name: Assert that primary cluster script was successful
          assert:
            that: result.stdout is search('may be running elasticsearch already')
            msg: "Cluster script may not have been successfully executed. Check the execution output below for more details. {{ result.stdout }}"
          when: groups['primary_vstats'] is defined and active and result.rc != 0

        - name: Execute VSTAT cluster script on standalone or clustered vsds for backup vstats
          command: /opt/vsd/vsd-es-cluster-config.sh -e {{ groups['backup_vstats'][0] }},{{ groups['backup_vstats'][1] }},{{ groups['backup_vstats'][2] }}
          environment:
            SSHPASS: "{{ vstat_default_password }}"
          when: groups['backup_vstats'] is defined and not active
          no_log: "{{ lookup('env', 'METROAE_NO_LOG') or 'true' }}"
          retries: 3
          delay: 10
          register: result
          until: result.rc == 0 or result.stdout is search('may be running elasticsearch already')
          ignore_errors: True

        - name: Assert that backup cluster script was successful
          assert:
            that: result.stdout is search('may be running elasticsearch already')
            msg: "Cluster script may not have been successfully executed. Check the execution output below for more details. {{ result.stdout }}"
          when: groups['backup_vstats'] is defined and not active and result.rc != 0

        when: vstat_sa_or_ha is match('ha')
        run_once: True

      delegate_to: "{{ hostvars[inventory_hostname].vsd_hostname_list[0] }}"
      remote_user: "{{ hostvars[hostvars[inventory_hostname].vsd_hostname_list[0]].vsd_custom_username | default(vsd_custom_username | default(vsd_default_username)) }}"
      become: >-
        {{ 'no' if hostvars[inventory_hostname].vsd_hostname_list[0].vsd_custom_username | default(vsd_custom_username | default(vsd_default_username)) == 'root' else 'yes' }}
      vars:
        ansible_become_pass: "{{ hostvars[inventory_hostname].vsd_hostname_list[0].vsd_custom_password | default(vsd_custom_password | default(vsd_default_password)) }}"

  - name: Update elasticsearch data path
    lineinfile:
      path: /etc/elasticsearch/elasticsearch.yml
      line: "path.data: {{ extra_disk_mount_point }}/elasticsearch"
      regexp: 'path.data:'
    when:
      - add_extra_disk | default(False)
      - extra_disk_mount_point | default("/var/lib/elasticsearch/") is not match("/var/lib/elasticsearch/")
    remote_user: "{{ vstat_default_username }}"

  - name: Execute yum update for vstat
    include_role:
      name: common
      tasks_from: yum-update.yml

  - name: Disable cloud-init on VSTAT, to avoid boot time delays
    command: "{{ item }}"
    with_items:
      - systemctl disable cloud-init
      - systemctl disable cloud-init-local
      - systemctl disable cloud-config
      - systemctl disable cloud-final
    remote_user: "{{ vstat_default_username }}"

  - name: Disable chrony on VSTAT if present
    systemd:
      name: "chronyd"
      enabled: no
      state: stopped
    remote_user: "{{ vstat_default_username }}"
    register: disable_chrony
    failed_when: disable_chrony is failed and not 'Could not find the requested service' in disable_chrony.msg

  - name: Enable stats
    include_role:
      name: common
      tasks_from: vstat-enable-stats.yml
    vars:
      failover: False
    loop: "{{ groups['primary_vsds'] }}"
    loop_control:
      loop_var: vsd
    run_once: true
    when: not stats_out | default(false)

  - name: Enable VSS UI
    import_tasks: setup-vstat-vss-ui.yml
    when: enable_vss_ui | default(False)

  - name: Configure ES primary and backup cluster
    include_role:
      name: common
      tasks_from: vstat-nfs-configuration.yml
    vars:
      deploy: True

    when: nfs_backup_location is defined

  - name: Setup health monitoring
    include_role:
      name: setup-health-monitoring
    vars:
      component_username: "{{ vstat_default_username }}"
    when: health_monitoring_agent | default("none") != "none"
    
  - block:

    - name: Adding the additional data nodes to existing elasticsearch cluster
      command: /root/nuage_elasticsearch/scripts/es-cluster-add-node.sh -e {{ groups['vstats'][0] }},{{ groups['vstats'][1] }},{{ groups['vstats'][2] }} -y
      retries: 3
      delay: 10
      register: cmdresult
      until: cmdresult.stdout is search('already running elastic search')
      ignore_errors: True

    - name: Assert that addition of node was successful
      assert:
        that: cmdresult.stdout is search('already running elastic search')
        msg: "Cluster add node script may not have been successfully executed. Check the execution output below for more details. {{ cmdresult.stdout }}"      
    
    when: 
      - groups['add_data_vstats'] is defined and inventory_hostname in groups['add_data_vstats']
      - groups['vstats'] is defined
      - add_extra_3_data_nodes

  when: not skip_vstat_deploy
