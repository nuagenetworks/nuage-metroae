---
- block:
  - name: Stop vsd services gracefully
    include_role:
      name: vsd-services-stop
    when:
    - inventory_hostname in groups['vsd_ha_node1'] or inventory_hostname in groups['vsd_ha_node3']
    remote_user: root
  when: vsd_sa_or_ha == 'ha'

- name: Shutdown/Destroy Current vsd node(s)
  include_role: 
    name: vsd-destroy
  vars:
    preserve_vsd: True
    rollback: False

- name: Deploy VSD nodes with new version
  include_role:
    name: vsd-predeploy

- name: Wait for VSD ssh to be ready
  local_action:
    module: wait_for
    port: "22"
    host: "{{ mgmt_ip }}"
    search_regex: OpenSSH
    delay: 1

- include: vsd_post_upgrade_helper.yml
  tags: 
   - vcin
   - vsd

- include: copy_backup_files.yml
  tags:
   - vcin
   - vsd

#TODO: 
#- name: Compare network information of VSD's across pre-uppgrade and upgrade

- name: Install VSD on new node(s)
  include_role:
    name: vsd-deploy

#TODO
#Add polling of VSD processes similar to VNS deploy instead of fix timeout
- name: Pause to wait for VSD processes to come up
  pause:
    minutes: 10

#TODO:
#-update vsd_post_upgrade_helper to include disabling VSD maintenance mode
- block:
  - name: Disable maintainance mode on all l3/l2 domains
    vsd_maintainance:
      vsd_auth:
        "{{ vsd_auth }}"
      state: disabled
    register: mode_status
    delegate_to: 127.0.0.1

  - name: Print vsd maintainance mode output when verbosity >= 1
    debug: var=mode_status verbosity=1

  - name: Clean known_hosts of VSC 1 on "{{ target_server }}"
    command: ssh-keygen -R "{{  groups['vscs'][0] }}" -f /root/.ssh/known_hosts
    delegate_to: "{{ ansible_deployment_host }}"
    remote_user: "{{ ansible_sudo_username }}"

  - name: Clean known_hosts of VSC 2 on "{{ target_server }}"
    command: ssh-keygen -R "{{  groups['vscs'][1] }}" -f /root/.ssh/known_hosts
    delegate_to: "{{ ansible_deployment_host }}"
    remote_user: "{{ ansible_sudo_username }}"

  - name: shut/noshut vswitch controller on vsc1 after disabling VSD maintenance mode
    sros_config:
      lines:
          - configure vswitch-controller shutdown
          - configure vswitch-controller no shutdown
      provider: 
        host: "{{ groups['vscs'][0] }}"
        username: "{{ vsc_user }}"
        password: "{{ vsc_password }}"
        transport: cli 
    register: vsc1_command_status
    delegate_to: "{{ ansible_deployment_host }}"
    remote_user: "{{ ansible_sudo_username }}"

  - debug: var=vsc1_command_statusa verbosity=1

  - name: shut/noshut vswitch controller on vsc2 after disabling VSD maintenance mode
    sros_config:
      lines:
          - configure vswitch-controller shutdown
          - configure vswitch-controller no shutdown
      provider: 
        host: "{{ groups['vscs'][1] }}"
        username: "{{ vsc_user }}"
        password: "{{ vsc_password }}"
        transport: cli 
    register: vsc2_command_status verbosity=1
    delegate_to: "{{ ansible_deployment_host }}"
    remote_user: "{{ ansible_sudo_username }}"

  - debug: var=vsc2_command_status verbosity=1

  - name: read saved vsd purge time before upgrade
    command: cat "/tmp/backup-{{ groups['vsd_ha_node1'][0] }}-latest/purge_time"
    register: purge_time_saved
    delegate_to: 127.0.0.1

  - debug: var=purge_time_saved.stdout verbosity=1

  - name: Update gateway purge timer to original value
    config_vsd_system:
      vsd_auth:
        "{{ vsd_auth }}"
      gateway_purge_time: "{{ purge_time_saved.stdout }}"
    register: update_time_status
    delegate_to: 127.0.0.1

  when: (inventory_hostname == groups['vsds'][0] and vsd_sa_or_ha == "sa") or (inventory_hostname == groups['vsds'][1] and vsd_sa_or_ha == "ha")
